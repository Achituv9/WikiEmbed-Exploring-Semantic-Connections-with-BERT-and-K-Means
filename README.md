The challenge of this project was to evaluate the effectiveness of the BERT model.

We embedded approximately 2.5 million Wikipedia pages and utilized K-means clustering and a Lovain network to assess the quality of the embeddings.

Our analysis successfully revealed meaningful connections between related articles, demonstrating the potential of the embeddings to capture semantic relationships.

the full explain of what we did find in the "Clustering Wikipedia Articles Using BERT and K-Means.pdf" file.

the data of this project is https://www.kaggle.com/datasets/ltcmdrdata/plain-text-wikipedia-202011

you need to unjip the folder before running the codes. 

the coeds py file need to be in same path the unnzip folder found

then you need to runs the code acorrding this order


